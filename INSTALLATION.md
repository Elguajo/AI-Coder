# Руководство по установке Elcoder

В этом руководстве описаны все шаги для установки и настройки Elcoder - локального ассистента по программированию.

## Системные требования

- **Операционная система**: Windows 10/11, macOS, или Linux
- **Python**: версия 3.10 или выше
- **Свободное место на диске**: минимум 5 ГБ (для установки моделей)
- **Оперативная память**: рекомендуется минимум 8 ГБ, оптимально 16 ГБ
- **GPU**: опционально, но рекомендуется для более быстрой работы моделей

## Пошаговая установка

### 1. Установка Python 3.10+

Скачайте и установите Python 3.10 или более новую версию с [официального сайта](https://www.python.org/downloads/).

Убедитесь, что Python добавлен в переменную PATH вашей системы.

### 2. Установка Ollama

Ollama — это платформа для запуска моделей локально.

#### Windows
1. Скачайте установщик с [официального сайта Ollama](https://ollama.ai/download)
2. Запустите установщик и следуйте инструкциям
3. После установки запустите Ollama из меню Пуск

#### macOS
1. Скачайте установщик с [официального сайта Ollama](https://ollama.ai/download)
2. Установите приложение в папку Applications
3. Запустите Ollama

#### Linux
```bash
curl -fsSL https://ollama.ai/install.sh | sh
ollama serve
```

### 3. Клонирование репозитория Elcoder

```bash
git clone https://github.com/ваш-аккаунт/elcoder.git
cd elcoder
```

### 4. Создание виртуального окружения (рекомендуется)

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 5. Установка зависимостей

```bash
pip install -r requirements.txt
```

### 6. Загрузка модели DeepSeek-coder

Запустите следующую команду для загрузки модели через Ollama:

```bash
ollama pull deepseek-coder:6.7b-instruct-q4_K_M
```

Этот процесс может занять некоторое время в зависимости от скорости вашего интернет-соединения. Модель занимает около 4-5 ГБ.

### 7. Настройка конфигурации (опционально)

Вы можете изменить настройки в файле `config.py`, включая:
- Используемую модель
- Параметры генерации
- Настройки сервера
- Директории для файлов

## Запуск Elcoder

### Запуск с настройками по умолчанию

```bash
python run.py
```

### Запуск с дополнительными параметрами

```bash
# Запуск с указанием типа интерфейса
python run.py --ui [basic|enhanced|custom]

# Запуск на другом порту
python run.py --port 8080

# Запуск с публичной ссылкой
python run.py --share

# Запуск с другой моделью
python run.py --model codellama:7b-instruct-q4_K_M
```

### Запуск API-сервера (для интеграции с другими приложениями)

```bash
python api.py
```

## Проверка установки

После запуска Elcoder будет доступен по адресу `http://localhost:7860` (или другому, если вы изменили порт). Откройте этот адрес в браузере.

## Решение проблем

### Ollama не запускается

1. Убедитесь, что Ollama установлен корректно
2. Перезапустите сервис Ollama:
   ```bash
   # Windows: перезапустите из меню Пуск
   # macOS: перезапустите приложение
   # Linux
   sudo systemctl restart ollama
   ```

### Модель не загружается

1. Проверьте наличие доступных моделей:
   ```bash
   ollama list
   ```
2. Попробуйте загрузить модель вручную:
   ```bash
   ollama pull deepseek-coder:6.7b-instruct-q4_K_M
   ```

### Проблемы с Python или зависимостями

```bash
pip install --upgrade pip
pip install --upgrade -r requirements.txt
```

### Недостаточно памяти

Если у вас возникают проблемы с недостатком памяти, попробуйте:
1. Использовать меньшую квантизованную модель (например, с суффиксом q4_0)
2. Закрыть другие ресурсоемкие приложения
3. Увеличить размер файла подкачки

## Обновление Elcoder

Для обновления до последней версии:

```bash
cd elcoder
git pull
pip install -r requirements.txt
```

## Дополнительные ресурсы

- [Документация Ollama](https://github.com/ollama/ollama/blob/main/README.md)
- [Документация LangChain](https://python.langchain.com/docs/get_started/introduction)
- [Документация Gradio](https://www.gradio.app/docs)
