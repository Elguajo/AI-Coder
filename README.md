## Локальный Чат-бот для Кодинга: Полная Документация

## Содержание
1. [Обзор проекта](#обзор-проекта)
2. [Архитектура системы](#архитектура-системы)
3. [Компоненты](#компоненты)
4. [Установка и запуск](#установка-и-запуск)
5. [Изменение UI (Frontend)](#изменение-ui-frontend)
6. [API-интерфейс](#api-интерфейс)
7. [Кастомизация модели](#кастомизация-модели)
8. [Часто задаваемые вопросы](#часто-задаваемые-вопросы)

## Обзор проекта

Этот проект представляет собой локальный чат-бот для программирования, который позволяет пользователям получать помощь в написании кода, решении задач программирования и работе с файлами. Система работает полностью локально, без необходимости подключения к внешним API.

**Ключевые возможности:**
- Генерация и объяснение кода
- Создание и редактирование файлов
- Выполнение кода Python в реальном времени
- Сохранение истории диалогов
- Полностью локальное использование без интернета

**Используемые технологии:**
- **Gradio**: для создания веб-интерфейса
- **LangChain**: фреймворк для работы с языковыми моделями
- **Ollama**: локальный сервер моделей
- **DeepSeek-coder**: языковая модель для программирования
- **Python 3.10**: язык разработки бэкенда
- **FastAPI**: для создания API (в расширенной версии)
- **React**: для альтернативного frontend (в расширенной версии)

## Архитектура системы

Система состоит из нескольких слоев:

1. **Уровень модели**:
   - Ollama для запуска DeepSeek-coder локально
   - LangChain для управления контекстом и памятью

2. **Уровень бизнес-логики**:
   - Обработка запросов пользователя
   - Работа с файлами
   - Выполнение кода

3. **Уровень представления**:
   - Веб-интерфейс на базе Gradio
   - Альтернативный интерфейс на React (в расширенной версии)
   - API на FastAPI (в расширенной версии)

### Схема взаимодействия компонентов

```
+-----------------+        +----------------+        +-------------------+
|                 |        |                |        |                   |
|  Web Interface  |<------>|  Core Logic   |<------>|   Language Model  |
| (Gradio/React)  |        | (LangChain)   |        |  (DeepSeek-coder) |
|                 |        |                |        |                   |
+-----------------+        +----------------+        +-------------------+
                                   ^
                                   |
                                   v
                           +----------------+
                           |                |
                           |  File System   |
                           |                |
                           +----------------+
```

## Компоненты

### Основные файлы проекта

| Файл | Описание |
|------|----------|
| `main.py` | Основной скрипт с базовым интерфейсом |
| `enhanced_chatbot.py` | Расширенная версия чат-бота |
| `custom_ui.py` | Кастомный интерфейс с улучшенным дизайном |
| `config.py` | Файл конфигурации |
| `run.py` | Скрипт для запуска с параметрами командной строки |
| `api.py` | FastAPI сервер для интеграции с внешними фронтендами |
| `requirements.txt` | Зависимости проекта |

### Дополнительные директории

| Директория | Описание |
|------------|----------|
| `assets/` | Директория для CSS, изображений и других ресурсов |
| `files/` | Директория для файлов, создаваемых чат-ботом |
| `react-frontend/` | Пример альтернативного фронтенда на React |

## Установка и запуск

Подробные инструкции по установке и запуску находятся в файле [Документация: Установка и запуск](installation-guide).

Основные шаги:

1. Установите Python 3.10 или новее
2. Установите Ollama с официального сайта
3. Клонируйте репозиторий и перейдите в директорию проекта
4. Создайте виртуальное окружение (рекомендуется)
5. Установите зависимости: `pip install -r requirements.txt`
6. Загрузите модель DeepSeek-coder: `ollama pull deepseek-coder:6.7b-instruct-q4_K_M`
7. Запустите чат-бота: `python run.py`

## Изменение UI (Frontend)

Подробное руководство по кастомизации интерфейса находится в файле [Руководство по изменению UI](ui-customization-guide).

Существует три основных подхода к изменению интерфейса:

1. **Изменение CSS стилей**:
   - Простой способ изменить внешний вид без изменения функциональности
   - Редактируйте файл `assets/custom.css`

2. **Модификация Gradio-интерфейса**:
   - Изменение структуры и компонентов интерфейса
   - Редактируйте файл `custom_ui.py`

3. **Полное разделение frontend и backend**:
   - Создание API для взаимодействия с бэкендом (`api.py`)
   - Разработка отдельного фронтенда с использованием любого фреймворка (пример на React)

## API-интерфейс

В расширенной версии проекта реализован API-интерфейс для взаимодействия с чат-ботом. Это позволяет разрабатывать собственные фронтенды или интегрировать чат-бот с другими приложениями.

### Запуск API-сервера

```bash
python api.py
```

По умолчанию сервер запускается на `http://127.0.0.1:8000`.

### Доступные эндпоинты

| Метод | Эндпоинт | Описание |
|-------|----------|----------|
| GET | `/` | Получение статуса API |
| POST | `/chat` | Отправка сообщения в чат |
| GET | `/files` | Получение списка файлов |
| GET | `/files/{filename}` | Получение содержимого файла |
| POST | `/files` | Создание или обновление файла |
| POST | `/execute` | Выполнение кода Python |
| GET | `/health` | Проверка работоспособности API |
| GET | `/config` | Получение текущей конфигурации |

### Примеры использования API

#### Отправка запроса в чат

```python
import requests
import json

response = requests.post(
    "http://localhost:8000/chat",
    headers={"Content-Type": "application/json"},
    data=json.dumps({
        "message": "Напиши функцию для сортировки списка",
        "history": []
    })
)

print(response.json())
```

#### Создание файла

```python
import requests
import json

response = requests.post(
    "http://localhost:8000/files",
    headers={"Content-Type": "application/json"},
    data=json.dumps({
        "filename": "sort.py",
        "content": "def sort_list(items):\n    return sorted(items)"
    })
)

print(response.json())
```

## Кастомизация модели

### Использование других моделей

Вы можете использовать другие модели, доступные в Ollama. Для этого:

1. Загрузите нужную модель с помощью Ollama:
   ```bash
   ollama pull llama2:7b
   ```

2. Укажите название модели при запуске:
   ```bash
   python run.py --model llama2:7b
   ```

Или измените параметр `MODEL_NAME` в файле `config.py`.

### Настройка параметров генерации

Вы можете настроить параметры генерации модели, изменив следующие параметры в файле `config.py`:

```python
# Температура генерации (0.0 - 1.0)
# Меньшие значения делают вывод более детерминированным
TEMPERATURE = 0.7

# Максимальное количество токенов в ответе
MAX_TOKENS = 2048
```

### Настройка системного промпта

Для изменения поведения модели вы можете настроить системный промпт, редактируя константу `PROMPT_TEMPLATE` в файле `enhanced_chatbot.py`:

```python
CODING_PROMPT_TEMPLATE = """
Ты - полезный ассистент по программированию на основе DeepSeek-coder. 
Ты специализируешься на написании кода, объяснении концепций программирования и решении технических проблем.
Твои ответы должны быть точными, полезными и следовать лучшим практикам программирования.

# Дополнительные инструкции можно добавить здесь

История разговора:
{history}

Пользователь: {input}
Ассистент:"""
```

## Часто задаваемые вопросы

### Каковы системные требования?

- **ОС**: Windows 10/11, macOS или Linux
- **Python**: версия 3.10 или выше
- **RAM**: минимум 8 ГБ, рекомендуется 16 ГБ
- **Процессор**: многоядерный современный процессор
- **Дисковое пространство**: минимум 5 ГБ для установки модели
- **GPU**: опционально, но рекомендуется для более быстрой работы

### Какие модели можно использовать?

Можно использовать любую модель, доступную в Ollama. Рекомендуемые модели для программирования:
- `deepseek-coder:6.7b-instruct-q4_K_M` (по умолчанию)
- `codellama:7b-instruct`
- `codellama:13b-instruct`
- `wizardcoder:7b`

### Как добавить новые функции в чат-бот?

Для добавления новых функций:

1. Добавьте новый метод в класс `EnhancedCodingChatBot` в файле `enhanced_chatbot.py`
2. Добавьте соответствующие элементы интерфейса в файл `custom_ui.py`
3. Свяжите функцию с элементами интерфейса

Пример добавления функции для анализа кода:

```python
# В enhanced_chatbot.py
def analyze_code(self, code):
    """
    Анализ кода на потенциальные проблемы
    """
    prompt = f"Проанализируй следующий код и найди проблемы:\n\n{code}"
    return self.chat(prompt, [])

# В custom_ui.py
analyze_btn = gr.Button("Анализировать код")
analyze_btn.click(bot.analyze_code, inputs=[code_input], outputs=[analysis_output])
```

### Как сделать модель более быстрой?

Для повышения скорости работы:

1. Используйте меньшие модели (например, 7B версии)
2. Используйте квантизованные версии моделей (с суффиксами q4, q5, q8)
3. Используйте GPU, если доступен
4. Уменьшите максимальное количество токенов в ответе в `config.py`

### Можно ли использовать чат-бот без интернета?

Да, после загрузки модели чат-бот работает полностью в автономном режиме без необходимости подключения к интернету.

### Как обновить модель?

Для обновления модели:

```bash
ollama pull deepseek-coder:6.7b-instruct-q4_K_M
```

### Как настроить количество сообщений, хранящихся в памяти?

Измените параметр `MEMORY_SIZE` в файле `config.py`:

```python
# Количество сообщений, хранящихся в памяти
MEMORY_SIZE = 10
```
