# Быстрый старт

## Установка

1. Убедитесь, что у вас установлен Python 3.10 или выше
2. Установите Ollama с сайта [https://ollama.ai/download](https://ollama.ai/download)
3. Запустите Ollama:
   ```bash
   ollama serve
   ```
4. Клонируйте репозиторий или распакуйте архив
5. Перейдите в директорию проекта
6. Запустите скрипт установки:
   ```bash
   python setup.py
   ```

## Запуск

1. Убедитесь, что Ollama запущена
2. Запустите чат-бот:
   ```bash
   python app.py
   ```
3. Откройте веб-интерфейс по адресу, указанному в консоли (обычно http://127.0.0.1:7860)

## Основные команды

- **Генерация кода**: "Напиши функцию для..."
- **Объяснение кода**: "Объясни этот код: ..."
- **Отладка кода**: "Исправь ошибки в этом коде: ..."
- **Работа с файлами**: "Список файлов", "Прочитай файл ...", "Выполни файл ..."

------------------------------------------------

# DeepSeek Coder Чат-бот - Документация

## Содержание

1. [Введение](#введение)
2. [Требования](#требования)
3. [Установка](#установка)
4. [Настройка](#настройка)
5. [Запуск](#запуск)
6. [Использование](#использование)
7. [Функциональность](#функциональность)
8. [Устранение неполадок](#устранение-неполадок)
9. [Расширение функциональности](#расширение-функциональности)

## Введение

DeepSeek Coder Чат-бот - это локальное приложение для работы с кодом, использующее языковую модель DeepSeek-coder через Ollama. Чат-бот предоставляет удобный веб-интерфейс на базе Gradio и имеет расширенные возможности для работы с кодом, включая генерацию, анализ, отладку и выполнение кода.

Основные компоненты:
- **Gradio** - веб-интерфейс
- **LangChain** - фреймворк для работы с языковыми моделями
- **Ollama** - локальный сервер для запуска моделей
- **DeepSeek-coder** - языковая модель для работы с кодом
- **ChromaDB** - векторная база данных для хранения памяти

## Требования

Для работы чат-бота необходимы следующие компоненты:

- Python 3.10 или выше
- Ollama (установленная и запущенная)
- Минимум 8 ГБ оперативной памяти (рекомендуется 16 ГБ)
- Минимум 10 ГБ свободного места на диске
- Подключение к интернету (для первоначальной загрузки модели)

## Установка

### 1. Установка Python

Если Python 3.10 или выше не установлен, установите его:

**Ubuntu/Debian:**
```bash
sudo apt update
sudo apt install python3 python3-pip python3-venv
```

**macOS:**
```bash
brew install python
```

**Windows:**
Скачайте и установите Python с [официального сайта](https://www.python.org/downloads/).

### 2. Установка Ollama

Установите Ollama, следуя инструкциям на [официальном сайте](https://ollama.ai/download):

**Linux:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

**macOS:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

**Windows:**
Скачайте и установите Ollama с [официального сайта](https://ollama.ai/download).

### 3. Клонирование репозитория

Клонируйте репозиторий или создайте структуру проекта вручную:

```bash
git clone https://github.com/yourusername/deepseek-coder-chatbot.git
cd deepseek-coder-chatbot
```

Или создайте структуру проекта вручную:

```bash
mkdir -p deepseek-coder-chatbot
cd deepseek-coder-chatbot
mkdir -p memory code docs
```

### 4. Создание виртуального окружения

Создайте и активируйте виртуальное окружение:

```bash
python3 -m venv venv
source venv/bin/activate  # Linux/macOS
# или
venv\Scripts\activate  # Windows
```

### 5. Установка зависимостей

Установите необходимые пакеты:

```bash
pip install gradio langchain langchain-community ollama python-dotenv chromadb pygments
```

### 6. Копирование файлов проекта

Скопируйте все файлы проекта в соответствующие директории:

- `config.py` - корневая директория
- `memory_manager.py` - корневая директория
- `ollama_client.py` - корневая директория
- `chatbot.py` - корневая директория
- `deepseek_model.py` - корневая директория
- `enhanced_chatbot.py` - корневая директория
- `code_manager.py` - корневая директория
- `code_enabled_chatbot.py` - корневая директория
- `app.py` - корневая директория
- `ollama_integration.py` - корневая директория
- `memory_test.py` - корневая директория

## Настройка

### 1. Настройка Ollama

Запустите Ollama:

```bash
ollama serve
```

### 2. Настройка переменных окружения

Создайте файл `.env` в корневой директории проекта:

```bash
touch .env
```

Добавьте следующие переменные окружения:

```
OLLAMA_BASE_URL=http://localhost:11434
MODEL_NAME=deepseek-coder
```

### 3. Настройка модели

При первом запуске чат-бота модель DeepSeek-coder будет автоматически загружена. Вы также можете загрузить модель вручную:

```bash
ollama pull deepseek-coder
```

### 4. Дополнительные настройки

Вы можете изменить настройки в файле `config.py`:

- `OLLAMA_BASE_URL` - URL для подключения к Ollama
- `MODEL_NAME` - название модели
- `MEMORY_DIR` - директория для хранения памяти
- `COLLECTION_NAME` - название коллекции в ChromaDB
- `GRADIO_THEME` - тема интерфейса Gradio
- `GRADIO_TITLE` - заголовок интерфейса
- `GRADIO_DESCRIPTION` - описание интерфейса
- `SYSTEM_PROMPT` - системный промпт для модели
- `MAX_CONTEXT_LENGTH` - максимальная длина контекста
- `CODE_DIR` - директория для хранения файлов с кодом

## Запуск

### 1. Запуск Ollama

Убедитесь, что Ollama запущена:

```bash
ollama serve
```

### 2. Запуск чат-бота

Активируйте виртуальное окружение (если еще не активировано):

```bash
source venv/bin/activate  # Linux/macOS
# или
venv\Scripts\activate  # Windows
```

Запустите чат-бот:

```bash
python app.py
```

После запуска в консоли появится URL для доступа к веб-интерфейсу, обычно это `http://127.0.0.1:7860`.

### 3. Проверка интеграции с Ollama

Вы можете проверить интеграцию с Ollama, запустив:

```bash
python ollama_integration.py
```

### 4. Тестирование памяти

Вы можете протестировать функциональность памяти, запустив:

```bash
python memory_test.py
```

## Использование

### Веб-интерфейс

Веб-интерфейс чат-бота состоит из следующих компонентов:

1. **Статус Ollama** - показывает текущий статус подключения к Ollama и модели
2. **Чат** - основной интерфейс для общения с чат-ботом
3. **Панель файлов и кода** - интерфейс для работы с файлами кода
4. **Настройки модели** - настройки модели и параметров генерации

### Основные функции

#### Общение с чат-ботом

1. Введите сообщение в поле ввода
2. Нажмите кнопку "Отправить" или клавишу Enter
3. Получите ответ от чат-бота

#### Работа с кодом

Чат-бот автоматически распознает запросы, связанные с кодом, и использует специализированные промпты для генерации кода, объяснения, отладки и рефакторинга.

Примеры запросов:
- "Напиши функцию для сортировки списка в Python"
- "Объясни следующий код: ..."
- "Найди и исправь ошибки в этом коде: ..."
- "Улучши этот код: ..."

#### Работа с файлами

Чат-бот автоматически сохраняет сгенерированный код в файлы и предоставляет команды для работы с ними:

- "Список файлов" - показать все сохраненные файлы
- "Прочитай файл имя_файла" - показать содержимое файла
- "Выполни файл имя_файла" - выполнить код из файла
- "Удали файл имя_файла" - удалить файл

Вы также можете использовать панель файлов и кода в веб-интерфейсе для работы с файлами:

1. Выберите файл из выпадающего списка
2. Используйте кнопки "Просмотреть", "Выполнить" или "Удалить"
3. Редактируйте код в редакторе и нажмите "Сохранить изменения"

#### Очистка чата и памяти

- Кнопка "Очистить чат" - очищает текущий чат
- Кнопка "Очистить память" - очищает долговременную память чат-бота

#### Настройки модели

В разделе "Настройки модели" вы можете изменить:
- Название модели
- Температуру генерации (влияет на креативность ответов)

## Функциональность

### Генерация кода

Чат-бот может генерировать код на различных языках программирования, включая Python, JavaScript, Java, C++, C#, PHP, Ruby, Go, Rust и другие.

### Объяснение кода

Чат-бот может объяснять предоставленный код, анализируя его структуру и функциональность.

### Отладка кода

Чат-бот может находить и исправлять ошибки в коде, предлагая исправления и объяснения.

### Рефакторинг кода

Чат-бот может улучшать и оптимизировать существующий код, делая его более читаемым, эффективным и поддерживаемым.

### Выполнение кода

Чат-бот может выполнять код на поддерживаемых языках (Python, JavaScript, Shell) и показывать результаты выполнения.

### Память

Чат-бот имеет долговременную память, которая позволяет ему запоминать предыдущие разговоры и использовать их для контекста в будущих ответах.

## Устранение неполадок

### Проблемы с подключением к Ollama

1. Убедитесь, что Ollama запущена:
   ```bash
   ollama serve
   ```

2. Проверьте URL для подключения к Ollama в файле `.env` или `config.py`:
   ```
   OLLAMA_BASE_URL=http://localhost:11434
   ```

3. Проверьте доступность Ollama API:
   ```bash
   curl http://localhost:11434/api/tags
   ```

### Проблемы с моделью

1. Убедитесь, что модель DeepSeek-coder загружена:
   ```bash
   ollama list
   ```

2. Если модель не загружена, загрузите её:
   ```bash
   ollama pull deepseek-coder
   ```

3. Проверьте название модели в файле `.env` или `config.py`:
   ```
   MODEL_NAME=deepseek-coder
   ```

### Проблемы с памятью

1. Проверьте права доступа к директории `memory`:
   ```bash
   ls -la memory
   ```

2. Очистите память, если возникают проблемы:
   ```bash
   rm -rf memory/*
   ```

### Проблемы с веб-интерфейсом

1. Убедитесь, что порт 7860 не занят другим приложением:
   ```bash
   lsof -i :7860
   ```

2. Запустите веб-интерфейс на другом порту:
   ```bash
   python app.py --port 7861
   ```

## Расширение функциональности

### Добавление новых моделей

Вы можете использовать другие модели, доступные в Ollama:

1. Загрузите модель:
   ```bash
   ollama pull modelname
   ```

2. Измените название модели в файле `.env` или `config.py`:
   ```
   MODEL_NAME=modelname
   ```

### Настройка системного промпта

Вы можете изменить системный промпт в файле `config.py` для настройки поведения чат-бота:

```python
SYSTEM_PROMPT = """Ваш новый системный промпт здесь"""
```

### Добавление новых функций

Для добавления новых функций вы можете модифицировать следующие файлы:

- `deepseek_model.py` - для добавления новых функций для работы с кодом
- `code_manager.py` - для добавления новых операций с файлами
- `app.py` - для изменения веб-интерфейса

### Интеграция с другими инструментами

Вы можете интегрировать чат-бот с другими инструментами, добавив соответствующие модули и функции в архитектуру проекта.


Подробная документация находится в файле [docs/README.md](docs/README.md)
