# Локальный чат-бот для кодинга: Руководство по установке и запуску

Данное руководство поможет вам установить и настроить локальный чат-бот для кодинга, использующий DeepSeek-coder через Ollama, с веб-интерфейсом на базе Gradio и функциональностью LangChain.

## Содержание

1. [Системные требования](#системные-требования)
2. [Установка необходимых компонентов](#установка-необходимых-компонентов)
   - [Python и зависимости](#python-и-зависимости)
   - [Ollama](#установка-ollama)
   - [Модель DeepSeek-coder](#установка-модели-deepseek-coder)
3. [Структура проекта](#структура-проекта)
4. [Настройка](#настройка)
5. [Запуск чат-бота](#запуск-чат-бота)
6. [Доступные интерфейсы](#доступные-интерфейсы)
7. [Использование чат-бота](#использование-чат-бота)
8. [Решение проблем](#решение-проблем)

## Системные требования

- **Операционная система**: Windows 10/11, macOS, или Linux
- **Python**: версия 3.10 или выше
- **Свободное место на диске**: минимум 5 ГБ (для установки моделей)
- **Оперативная память**: рекомендуется минимум 8 ГБ, оптимально 16 ГБ
- **GPU**: опционально, но рекомендуется для более быстрой работы моделей

## Установка необходимых компонентов

### Python и зависимости

1. Установите Python 3.10 или новее с [официального сайта](https://www.python.org/downloads/)

2. Клонируйте или распакуйте исходный код проекта в желаемую директорию

3. Откройте терминал/командную строку и перейдите в директорию проекта:
   ```bash
   cd путь/к/проекту
   ```

4. Рекомендуется создать виртуальное окружение:
   ```bash
   # Windows
   python -m venv venv
   venv\Scripts\activate

   # macOS/Linux
   python3 -m venv venv
   source venv/bin/activate
   ```

5. Установите необходимые зависимости:
   ```bash
   pip install -r requirements.txt
   ```

### Установка Ollama

Ollama – это инструмент для локального запуска моделей.

#### Windows

1. Скачайте установщик с [официального сайта Ollama](https://ollama.ai/download)
2. Запустите установщик и следуйте инструкциям
3. После установки запустите Ollama из меню Пуск

#### macOS

1. Скачайте установщик с [официального сайта Ollama](https://ollama.ai/download)
2. Установите приложение в папку Applications
3. Запустите Ollama

#### Linux

```bash
curl -fsSL https://ollama.ai/install.sh | sh
ollama serve
```

### Установка модели DeepSeek-coder

После установки Ollama, загрузите модель DeepSeek-coder:

```bash
ollama pull deepseek-coder:6.7b-instruct-q4_K_M
```

Загрузка может занять некоторое время в зависимости от скорости вашего интернет-соединения.

## Структура проекта

```
chatbot/
├── main.py             # Основной скрипт с базовым интерфейсом
├── enhanced_chatbot.py # Расширенная версия чат-бота
├── custom_ui.py        # Кастомный интерфейс
├── config.py           # Файл конфигурации
├── run.py              # Скрипт для запуска с параметрами командной строки
├── requirements.txt    # Зависимости проекта
├── assets/             # Директория для ресурсов (CSS, изображения)
└── files/              # Директория для файлов, создаваемых чат-ботом
```

## Настройка

Вы можете изменить настройки чат-бота, отредактировав файл `config.py`:

```python
# Настройки модели
MODEL_NAME = "deepseek-coder:6.7b-instruct-q4_K_M"  # Название модели
TEMPERATURE = 0.7  # Температура генерации (0.0 - 1.0)
MAX_TOKENS = 2048  # Максимальное количество токенов в ответе

# Настройки веб-интерфейса
SERVER_HOST = "127.0.0.1"  # Хост для запуска сервера
SERVER_PORT = 7860  # Порт для запуска сервера
SHARE = False  # Создать публичную ссылку
AUTH = None  # Авторизация в формате ("username", "password")

# Другие настройки...
```

## Запуск чат-бота

### Простой запуск

Для запуска чат-бота с настройками по умолчанию:

```bash
# Активируйте виртуальное окружение, если используете
# Windows: venv\Scripts\activate
# macOS/Linux: source venv/bin/activate

python run.py
```

### Запуск с параметрами

Вы можете указать параметры запуска:

```bash
# Запуск с базовым интерфейсом на порту 8080
python run.py --ui basic --port 8080

# Запуск с расширенным интерфейсом и публичной ссылкой
python run.py --ui enhanced --share

# Запуск с другой моделью
python run.py --model deepseek-coder:33b-instruct-q4_K_M
```

Доступные параметры:
- `--ui`: тип интерфейса (`basic`, `enhanced` или `custom`, по умолчанию `custom`)
- `--host`: хост для запуска сервера (по умолчанию из config.py)
- `--port`: порт для запуска сервера (по умолчанию из config.py)
- `--share`: создать публичную ссылку
- `--model`: название модели для использования

## Доступные интерфейсы

Чат-бот предлагает три типа интерфейса:

1. **Базовый (basic)**: Простой интерфейс с основными функциями чата и управления файлами
2. **Расширенный (enhanced)**: Интерфейс с дополнительными функциями для запуска кода и более удобной работы с файлами
3. **Кастомный (custom)**: Улучшенный интерфейс с кастомными стилями, дополнительными вкладками и настройками

## Использование чат-бота

После запуска чат-бота, откройте веб-браузер и перейдите по адресу:
```
http://127.0.0.1:7860
```
(если вы изменили порт, укажите его вместо 7860)

### Основные функции

1. **Чат**: Задавайте вопросы по программированию, запрашивайте код, просите объяснить концепции
2. **Работа с файлами**: 
   - Создание файлов: перейдите на вкладку "Файлы", введите имя файла, напишите код и нажмите "Сохранить файл"
   - Чтение файлов: введите имя файла и нажмите "Прочитать файл"
   - Список файлов: нажмите "Список файлов" для просмотра доступных файлов
3. **Запуск кода** (в расширенном и кастомном интерфейсах):
   - Введите код Python на вкладке "Запуск кода"
   - Нажмите "Выполнить код" для запуска и просмотра результатов

### Команды чата

В чате вы можете использовать специальные команды:

- `/file list` - получить список файлов
- `/file read имя_файла` - прочитать содержимое файла
- `/file create имя_файла содержимое` - создать файл с указанным содержимым

## Решение проблем

### Ollama не запускается или не отвечает

1. Убедитесь, что Ollama установлен корректно
2. Перезапустите сервис Ollama:
   ```bash
   # Windows: перезапустите из меню Пуск
   # macOS: перезапустите приложение
   # Linux
   sudo systemctl restart ollama
   ```

### Модель не загружается

1. Проверьте наличие доступных моделей:
   ```bash
   ollama list
   ```
2. Попробуйте загрузить модель вручную:
   ```bash
   ollama pull deepseek-coder:6.7b-instruct-q4_K_M
   ```

### Проблемы с зависимостями

Если сталкиваетесь с ошибками импорта или отсутствующими модулями:
```bash
pip install --upgrade -r requirements.txt
```

### Конфликты портов

Если порт 7860 уже занят, вы можете указать другой порт при запуске:
```bash
python run.py --port 8080
```

## Дополнительная информация

- **Логи**: По умолчанию логи выводятся в терминал. Уровень логирования можно изменить в файле `config.py` (LOG_LEVEL)
- **Файлы**: По умолчанию файлы сохраняются в директории `files` внутри проекта
- **Память**: Память чат-бота ограничена последними 10 сообщениями (настраивается в `config.py` через MEMORY_SIZE)
